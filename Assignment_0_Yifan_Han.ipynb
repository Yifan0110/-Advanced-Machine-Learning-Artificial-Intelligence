{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 0, Yifan Han, Oct 11 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import date\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data\n",
    "months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\",\n",
    "          \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "inputs = \"\".join(set(\"\".join(months) + \"1234567890\" +  \" ,\"))\n",
    "outputs = \"-1234567890\"\n",
    "\n",
    "def random_dates(n_dates):\n",
    "    min_date = date(1900, 1, 1).toordinal()\n",
    "    max_date = date(2500, 12, 31).toordinal()\n",
    "\n",
    "    ordinals = np.random.randint(min_date, max_date, size=n_dates)\n",
    "    dates = [date.fromordinal(ordinal) for ordinal in ordinals]\n",
    "\n",
    "    x = [f\"{months[dt.month - 1]} {dt.strftime('%d, %Y')}\" for dt in dates]\n",
    "    y = [dt.isoformat() for dt in dates]\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def convert_date_string_to_ids(date_string, char_set=inputs):\n",
    "    return [char_set.find(char) for char in date_string]\n",
    "\n",
    "def format_date_strings(date_list, char_set=inputs):\n",
    "    index_lists = [convert_date_string_to_ids(date, char_set) for date in date_list]\n",
    "    tensor_data = tf.ragged.constant(index_lists, ragged_rank=1)\n",
    "    return (tensor_data + 1).to_tensor()\n",
    "\n",
    "\n",
    "def generate_data(num_dates):\n",
    "    x, y = random_dates(num_dates)\n",
    "    return format_date_strings(x, inputs), format_date_strings(y, outputs)\n",
    "\n",
    "np.random.seed(2024)\n",
    "\n",
    "X_train, Y_train = generate_data(20000)\n",
    "X_valid, Y_valid = generate_data(1000)\n",
    "X_test, Y_test = generate_data(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 13s 16ms/step - loss: 1.4580 - accuracy: 0.4729 - val_loss: 1.0722 - val_accuracy: 0.6118\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.7428 - accuracy: 0.7226 - val_loss: 0.5099 - val_accuracy: 0.8037\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 10s 15ms/step - loss: 0.3258 - accuracy: 0.8815 - val_loss: 0.1597 - val_accuracy: 0.9577\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.0850 - accuracy: 0.9834 - val_loss: 0.0402 - val_accuracy: 0.9959\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.0225 - accuracy: 0.9986 - val_loss: 0.0126 - val_accuracy: 0.9994\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 11s 17ms/step - loss: 0.0084 - accuracy: 0.9998 - val_loss: 0.0060 - val_accuracy: 0.9999\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 11s 17ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 0.0646 - accuracy: 0.9864 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 13s 21ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 12s 19ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 12s 20ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 12s 18ms/step - loss: 8.9099e-04 - accuracy: 1.0000 - val_loss: 7.6968e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 11s 17ms/step - loss: 6.0542e-04 - accuracy: 1.0000 - val_loss: 5.3382e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 4.1886e-04 - accuracy: 1.0000 - val_loss: 3.7609e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 12s 19ms/step - loss: 2.9234e-04 - accuracy: 1.0000 - val_loss: 2.6639e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 11s 18ms/step - loss: 2.0536e-04 - accuracy: 1.0000 - val_loss: 1.8413e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 11s 18ms/step - loss: 1.4501e-04 - accuracy: 1.0000 - val_loss: 1.2990e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 10s 16ms/step - loss: 1.0279e-04 - accuracy: 1.0000 - val_loss: 9.2200e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 10s 17ms/step - loss: 7.3037e-05 - accuracy: 1.0000 - val_loss: 6.5679e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 11s 17ms/step - loss: 5.1686e-05 - accuracy: 1.0000 - val_loss: 4.6749e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Encoder-Decoder RNN model \n",
    "\n",
    "embedding_dim = 32\n",
    "max_output_length = Y_train.shape[1]\n",
    "\n",
    "np.random.seed(2024)\n",
    "tf.random.set_seed(2024)\n",
    "\n",
    "# Define the encoder model\n",
    "encoder_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(inputs) + 1,\n",
    "                               output_dim=embedding_dim,\n",
    "                               input_shape=[None]),\n",
    "    tf.keras.layers.LSTM(128)\n",
    "])\n",
    "\n",
    "# Define the decoder model\n",
    "decoder_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.LSTM(128, return_sequences=True),\n",
    "    tf.keras.layers.Dense(len(outputs) + 1, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Combine encoder and decoder into a full model\n",
    "full_model = tf.keras.Sequential([\n",
    "    encoder_model,\n",
    "    tf.keras.layers.RepeatVector(max_output_length),\n",
    "    decoder_model\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Nadam()\n",
    "full_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "                   metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "training_history = full_model.fit(X_train, Y_train, epochs=20,\n",
    "                                   validation_data=(X_valid, Y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 894ms/step\n",
      "['2002-01-10', '2000-05-26']\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "\n",
    "def ids_to_date_strings(ids, char_set=outputs):\n",
    "    return [\"\".join([(\"?\" + char_set)[index] for index in sequence])\n",
    "            for sequence in ids]\n",
    "\n",
    "max_input_length = X_train.shape[1]\n",
    "\n",
    "def prepare_padded_date_strings(date_strings):\n",
    "    tensor_X = format_date_strings(date_strings)\n",
    "    if tensor_X.shape[1] < max_input_length:\n",
    "        tensor_X = tf.pad(tensor_X, [[0, 0], [0, max_input_length - tensor_X.shape[1]]])\n",
    "    return tensor_X\n",
    "\n",
    "def convert_to_date_strings(date_strings):\n",
    "    padded_X = prepare_padded_date_strings(date_strings)\n",
    "    predicted_ids = full_model.predict(padded_X).argmax(axis=-1)\n",
    "    return ids_to_date_strings(predicted_ids)\n",
    "\n",
    "example_dates = [\"January 10, 2002\", \"May 26, 2000\"]\n",
    "converted_dates = convert_to_date_strings(example_dates)\n",
    "print(converted_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, Dense, LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_17 (SimpleRNN)   (None, None, 20)          440       \n",
      "                                                                 \n",
      " simple_rnn_18 (SimpleRNN)   (None, None, 20)          820       \n",
      "                                                                 \n",
      " simple_rnn_19 (SimpleRNN)   (None, 1)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,282\n",
      "Trainable params: 1,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Case 1: SimpleRNN with scalar input\n",
    "model_rnn_scalar = keras.models.Sequential([\n",
    "  keras.layers.SimpleRNN(20, return_sequences=True,\n",
    "                         input_shape=[None, 1]),\n",
    "  keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "  keras.layers.SimpleRNN(1)\n",
    "])\n",
    "model_rnn_scalar.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1:  SimpleRNN layers as on slides, at each time step x(t) is a scalar.\n",
    "\n",
    "#### Number of parameters = units x (units +input dimension +1)\n",
    "#### Layer 1: 20 x (20+1+1) =440 (units=20, input dimension=1 since x(t) is a scalar)\n",
    "#### Layer 2: 20 x (20+20+1) =820 (units=20, input dimension=20 since it has 20 units and return_sequences=True)\n",
    "#### Layer 3: 1 x (20+1+1) = 22 \n",
    "\n",
    "#### Total trainable parameters= 440+820+220=1282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_23 (SimpleRNN)   (None, None, 20)          480       \n",
      "                                                                 \n",
      " simple_rnn_24 (SimpleRNN)   (None, None, 20)          820       \n",
      "                                                                 \n",
      " simple_rnn_25 (SimpleRNN)   (None, 1)                 22        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,322\n",
      "Trainable params: 1,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Case 2: SimpleRNN with vector input\n",
    "model_rnn_vector = model_rnn_scalar = keras.models.Sequential([\n",
    "  keras.layers.SimpleRNN(20, return_sequences=True,\n",
    "                         input_shape=[None, 3]),\n",
    "  keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "  keras.layers.SimpleRNN(1)\n",
    "])\n",
    "model_rnn_vector.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2:  SimpleRNN layers as on slides, x(t) is a vector of 3 values.\n",
    "\n",
    "#### Layer 1: 20 x (20+3+1) =480 (units=20, input dimension=1 since x(t) is a vector of 3 values)\n",
    "#### Layer 2: 20 x (20+20+1) =820 (units=20, input dimension=20 since it has 20 units and return_sequences=True)\n",
    "#### Layer 3: 1 x (20+1+1) = 22 \n",
    "\n",
    "#### Total trainable parameters= 480+820+220=1322"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_31 (SimpleRNN)   (None, None, 20)          440       \n",
      "                                                                 \n",
      " simple_rnn_32 (SimpleRNN)   (None, None, 20)          820       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, None, 1)           21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,281\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Case 3: SimpleRNN + Dense(1)\n",
    "model_rnn_dense = keras.models.Sequential([\n",
    "  keras.layers.SimpleRNN(20, return_sequences=True,\n",
    "                         input_shape=[None, 1]),\n",
    "  keras.layers.SimpleRNN(20, return_sequences=True),\n",
    "  keras.layers.Dense(1)\n",
    "])\n",
    "model_rnn_dense.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 3:\n",
    "\n",
    "#### Number of parameters = units x (units +input dimension +1)\n",
    "#### Layer 1: 20 x (20+1+1) =440 \n",
    "#### Layer 2: 20 x (20+20+1) =820 \n",
    "#### Dense layer: Input Dimension×Output Dimension+Output Dimension = 20 x 1 +1 =21\n",
    "\n",
    "#### Total trainable parameters= 440+820+21=1281"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, None, 20)          1760      \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, None, 20)          3280      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, None, 1)           21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,061\n",
      "Trainable params: 5,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Case 4: LSTM + Dense(1)\n",
    "model_lstm_dense = keras.models.Sequential([\n",
    "  keras.layers.LSTM(20, return_sequences=True,\n",
    "                         input_shape=[None, 1]),\n",
    "  keras.layers.LSTM(20, return_sequences=True),\n",
    "  keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_lstm_dense.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 4:  LSTM + Dense(1)\n",
    "\n",
    "#### 4 weight matrices for the LSTM\n",
    "\n",
    "#### Number of parameters = weight x units x (units +input dimension +1)\n",
    "#### Layer 1: 4 x 20 x (20+1+1) =1760 \n",
    "#### Layer 2: 4 x 20 x (20+20+1) =3280\n",
    "#### Dense layer: Input Dimension×Output Dimension+Output Dimension = 20 x 1 +1 =21\n",
    "\n",
    "#### Total parameters= 1760+3280+21 = 5061"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " gru_3 (GRU)                 (None, None, 20)          1380      \n",
      "                                                                 \n",
      " gru_4 (GRU)                 (None, None, 20)          2520      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, None, 1)           21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,921\n",
      "Trainable params: 3,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Case 5: GRU + Dense(1)\n",
    "model_gru_dense = keras.models.Sequential([\n",
    "  keras.layers.GRU(20, return_sequences=True,\n",
    "                         input_shape=[None, 1]),\n",
    "  keras.layers.GRU(20, return_sequences=True),\n",
    "  keras.layers.Dense(1)\n",
    "])\n",
    "model_gru_dense.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 5:  GRU + Dense(1)\n",
    "\n",
    "#### 3 weight matrices for the GRU\n",
    "\n",
    "#### Number of parameters = weight x units x (units +input dimension +1)\n",
    "#### Layer 1: 3 x 20 x (20+1+1+1) =1380 (GRU has an extra bias due to reset-after mechanism) \n",
    "#### Layer 2: 3 x 20 x (20+20+1+1) = 2520\n",
    "#### Dense layer: Input Dimension×Output Dimension+Output Dimension = 20 x 1 +1 =21\n",
    "\n",
    "#### Total parameters= 1380+2520+21 = 3921\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
